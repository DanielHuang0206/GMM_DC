{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ä½ç§» = 0 (å…­ä½ç²¾åº¦) ===\n",
      "- è¡Œ 1: DeltaDist = 0\n",
      "- è¡Œ 11: DeltaDist = 0\n",
      "- è¡Œ 14: DeltaDist = 0\n",
      "- è¡Œ 15: DeltaDist = 0\n",
      "- è¡Œ 21: DeltaDist = 0\n",
      "- è¡Œ 24: DeltaDist = 0\n",
      "- è¡Œ 30: DeltaDist = 0\n",
      "- è¡Œ 31: DeltaDist = 0\n",
      "- è¡Œ 32: DeltaDist = 0\n",
      "- è¡Œ 33: DeltaDist = 0\n",
      "- è¡Œ 41: DeltaDist = 0\n",
      "- è¡Œ 44: DeltaDist = 0\n",
      "- è¡Œ 47: DeltaDist = 0\n",
      "- è¡Œ 50: DeltaDist = 0\n",
      "- è¡Œ 51: DeltaDist = 0\n",
      "- è¡Œ 57: DeltaDist = 0\n",
      "- è¡Œ 58: DeltaDist = 0\n",
      "- è¡Œ 64: DeltaDist = 0\n",
      "- è¡Œ 69: DeltaDist = 0\n",
      "- è¡Œ 70: DeltaDist = 0\n",
      "- è¡Œ 71: DeltaDist = 0\n",
      "- è¡Œ 72: DeltaDist = 0\n",
      "- è¡Œ 73: DeltaDist = 0\n",
      "- è¡Œ 74: DeltaDist = 0\n",
      "- è¡Œ 77: DeltaDist = 0\n",
      "- è¡Œ 96: DeltaDist = 0\n",
      "- è¡Œ 99: DeltaDist = 0\n",
      "- è¡Œ 102: DeltaDist = 0\n",
      "- è¡Œ 105: DeltaDist = 0\n",
      "- è¡Œ 109: DeltaDist = 0\n",
      "- è¡Œ 110: DeltaDist = 0\n",
      "- è¡Œ 113: DeltaDist = 0\n",
      "- è¡Œ 114: DeltaDist = 0\n",
      "- è¡Œ 118: DeltaDist = 0\n",
      "- è¡Œ 119: DeltaDist = 0\n",
      "================================\n",
      "\n",
      "âœ… å®Œæˆï¼è¼¸å‡ºï¼š/media/dc0206/Crucial X6/GMM20/20240329_DATA/NTHU_5x/red06/Result_with_disp.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "å›ºå®šè®€å–æŒ‡å®š Result.txtï¼Œè¨ˆç®—ç›¸é„°å…©ç­†ä½ç§»é‡ (6 ä½å°æ•¸)ï¼Œä¸¦è¼¸å‡º CSVã€‚\n",
    "åŸ·è¡Œï¼š\n",
    "    python compute_displacement_fixed.py\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import math\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== 1. æŒ‡å®šæª”æ¡ˆè·¯å¾‘ ==========================================\n",
    "TXT_FILE = Path(\"/media/dc0206/Crucial X6/GMM20/20240329_DATA/NTHU_5x/red06/Result.txt\")\n",
    "# ==============================================================\n",
    "\n",
    "# æ¬²æ¡ç”¨çš„æ¬„ä½\n",
    "X_COL = \"AeroCmdX\"\n",
    "Y_COL = \"AeroCmdY\"\n",
    "\n",
    "PAIR_RE = re.compile(r\"([\\w\\d]+):\\s*([-+]?[0-9]*\\.?[0-9]+)\")\n",
    "\n",
    "def parse_line(line: str):\n",
    "    return {k: float(v) for k, v in PAIR_RE.findall(line)}\n",
    "\n",
    "def main():\n",
    "    if not TXT_FILE.exists():\n",
    "        raise FileNotFoundError(f\"æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{TXT_FILE}\")\n",
    "\n",
    "    rows = []\n",
    "    with TXT_FILE.open(encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                rows.append(parse_line(line))\n",
    "    if not rows:\n",
    "        raise ValueError(\"æª”æ¡ˆå…§å®¹ç„¡å¯è§£æè³‡æ–™\")\n",
    "\n",
    "    # --- è¨ˆç®— Î”X, Î”Y, Î”Dist ----------------------------------\n",
    "    prev_x = prev_y = None\n",
    "    for r in rows:\n",
    "        cur_x, cur_y = r.get(X_COL), r.get(Y_COL)\n",
    "        if prev_x is None:\n",
    "            dx = dy = dist = 0.0\n",
    "        else:\n",
    "            dx, dy = cur_x - prev_x, cur_y - prev_y\n",
    "            dist = math.hypot(dx, dy)\n",
    "        # ğŸ”¸ å››æ¨äº”å…¥è‡³ 6 ä½\n",
    "        r.update(\n",
    "            DeltaX=round(dx, 6),\n",
    "            DeltaY=round(dy, 6),\n",
    "            DeltaDist=round(dist, 6)\n",
    "        )\n",
    "        prev_x, prev_y = cur_x, cur_y\n",
    "\n",
    "    # --- æ‰¾å‡ºä½ç§»ç‚º 0 çš„ç´€éŒ„ ---------------------------------\n",
    "    zero_moves = []\n",
    "    for idx, r in enumerate(rows, start=1):\n",
    "        if math.isclose(r[\"DeltaDist\"], 0.0, abs_tol=1e-10):   # ğŸ”¸\n",
    "            zero_moves.append((idx, r))\n",
    "\n",
    "    if zero_moves:\n",
    "        print(\"\\n=== ä½ç§» = 0 (å…­ä½ç²¾åº¦) ===\")\n",
    "        for idx, r in zero_moves:\n",
    "            if \"ImgName\" in r:\n",
    "                print(f\"- è¡Œ {idx}: {r['ImgName']}\")\n",
    "            else:\n",
    "                print(f\"- è¡Œ {idx}: DeltaDist = 0\")\n",
    "        print(\"================================\\n\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  æ²’æœ‰ DeltaDist = 0 çš„ç´€éŒ„\\n\")\n",
    "\n",
    "    # --- è¼¸å‡º CSV (å›ºå®š 6 ä½å°æ•¸) -----------------------------\n",
    "    out_path = TXT_FILE.with_name(TXT_FILE.stem + \"_with_disp.csv\")\n",
    "    fieldnames = rows[0].keys()\n",
    "    with out_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            # ğŸ”¸ è½‰æˆæ ¼å¼åŒ–å­—ä¸²ï¼Œç¢ºä¿ 6 ä½\n",
    "            r_fmt = {k: (f\"{v:.6f}\" if isinstance(v, float) else v) for k, v in r.items()}\n",
    "            writer.writerow(r_fmt)\n",
    "\n",
    "    print(f\"âœ… å®Œæˆï¼è¼¸å‡ºï¼š{out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"å¤šè³‡æ–™é›†é»é›²â€‘å½±åƒå°é½Šæ‰¹æ¬¡è™•ç†ç¨‹å¼\n",
    "------------------------------------------------\n",
    "ä½¿ç”¨æ–¹å¼ï¼š\n",
    "1. å…ˆåœ¨ DATASETS æ¸…å–®ä¸­å¡«å…¥æ¯å€‹è³‡æ–™é›†çš„è·¯å¾‘èˆ‡æª”åè¨­å®šã€‚\n",
    "2. åŸ·è¡Œ python multi_dataset_registration.py\n",
    "   -> ç¨‹å¼æœƒä¾åºè™•ç†æ‰€æœ‰è³‡æ–™å¤¾ï¼Œçµæœå„è‡ªè¼¸å‡ºç‚º Excelã€‚\n",
    "   -> è‹¥æŸè³‡æ–™é›†å¤±æ•—ï¼ŒéŒ¯èª¤è¨Šæ¯æœƒåˆ—å‡ºï¼Œä½†ä¸å½±éŸ¿å…¶ä»–æ‰¹æ¬¡ã€‚\n",
    "\n",
    "ç¨‹å¼å¤§ç¶±ï¼š\n",
    "    â”œâ”€ æ¼”ç®—æ³•å‡½å¼ï¼ˆè£œé»ã€DBSCAN éæ¿¾ã€USACã€ICP/CPD...ï¼‰\n",
    "    â”œâ”€ process_dataset(cfg): è™•ç†å–®ä¸€è³‡æ–™é›†\n",
    "    â””â”€ main(): è¿´åœˆå‘¼å« process_dataset()\n",
    "\"\"\"\n",
    "\n",
    "# === 0. å¥—ä»¶ ===\n",
    "import os, glob, time\n",
    "import numpy as np, pandas as pd, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pycpd import RigidRegistration  # pip install pycpd\n",
    "\n",
    "# ---------------------------\n",
    "# 1. è£œé»å‡½å¼\n",
    "# ---------------------------\n",
    "\n",
    "def ensure_two_points_in_circle_all(filtered_points, radius: float = 10.0):\n",
    "    \"\"\"ç¢ºä¿æ¯å€‹åœ“å½¢å€åŸŸå…§è‡³å°‘å…©é»ï¼Œå¦‚ä¸è¶³å‰‡è£œé»\"\"\"\n",
    "    if len(filtered_points) < 1:\n",
    "        return filtered_points, []\n",
    "\n",
    "    new_points = []\n",
    "    for i, center in enumerate(filtered_points):\n",
    "        dists = np.linalg.norm(filtered_points - center, axis=1)\n",
    "        in_circle_indices = np.where(dists <= radius)[0]\n",
    "        if len(in_circle_indices) < 2:\n",
    "            if len(filtered_points) == 1:\n",
    "                rand_dir = np.random.randn(2)\n",
    "                rand_dir /= (np.linalg.norm(rand_dir) + 1e-9)\n",
    "                new_pt = center + rand_dir * (radius * 0.5)\n",
    "                new_points.append(new_pt)\n",
    "            else:\n",
    "                sorted_idx = np.argsort(dists)\n",
    "                nearest_idx = sorted_idx[1] if sorted_idx[0] == i else sorted_idx[0]\n",
    "                nearest_point = filtered_points[nearest_idx]\n",
    "                direction_vec = center - nearest_point\n",
    "                dist_np = np.linalg.norm(direction_vec)\n",
    "                if dist_np < 1e-9:\n",
    "                    direction_vec = np.random.randn(2)\n",
    "                    dist_np = np.linalg.norm(direction_vec)\n",
    "                dir_unit = direction_vec / dist_np\n",
    "                new_pt = center + dir_unit * (radius * 0.8)\n",
    "                new_points.append(new_pt)\n",
    "\n",
    "    if len(new_points) > 0:\n",
    "        new_points = np.array(new_points)\n",
    "        updated_points = np.vstack([filtered_points, new_points])\n",
    "    else:\n",
    "        updated_points = filtered_points\n",
    "    return updated_points, new_points\n",
    "\n",
    "def ensure_two_points_in_circle_iterative(points, radius: float = 10.0, max_iter: int = 100):\n",
    "    updated_points = points.copy()\n",
    "    for _ in range(max_iter):\n",
    "        updated_points, new_points = ensure_two_points_in_circle_all(updated_points, radius=radius)\n",
    "        if len(new_points) == 0:\n",
    "            break\n",
    "    return updated_points\n",
    "\n",
    "# ---------------------------\n",
    "# 2. é›œè¨Šéæ¿¾èˆ‡è¼”åŠ©å‡½å¼\n",
    "# ---------------------------\n",
    "\n",
    "def filter_noise_points_weighted(points, eps: float = 3, min_samples: int = 2,\n",
    "                                 min_cluster_size: int = 55, return_mask: bool = False):\n",
    "    if len(points) == 0:\n",
    "        return np.array([]), np.array([]) if not return_mask else (np.array([]), np.array([]), None)\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(points)\n",
    "    labels = db.labels_\n",
    "    unique_labels, counts = np.unique(labels[labels != -1], return_counts=True)\n",
    "    large_clusters = set(unique_labels[counts >= min_cluster_size])\n",
    "    mask = np.isin(labels, list(large_clusters))\n",
    "    filtered_points = points[mask]\n",
    "    return (filtered_points, mask) if not return_mask else (filtered_points, mask, mask)\n",
    "\n",
    "def compute_local_density(points, k: int = 18):\n",
    "    if len(points) == 0:\n",
    "        return np.array([])\n",
    "    actual_k = min(k + 1, len(points))\n",
    "    nbrs = NearestNeighbors(n_neighbors=actual_k).fit(points)\n",
    "    distances, _ = nbrs.kneighbors(points)\n",
    "    avg_distance = np.mean(distances[:, 1:], axis=1)\n",
    "    density = 1.0 / (avg_distance + 1e-6)\n",
    "    return density\n",
    "\n",
    "def estimate_rigid_transform(src, dst):\n",
    "    centroid_src = np.mean(src, axis=0)\n",
    "    centroid_dst = np.mean(dst, axis=0)\n",
    "    src_centered = src - centroid_src\n",
    "    dst_centered = dst - centroid_dst\n",
    "    H = src_centered.T @ dst_centered\n",
    "    U, _, Vt = np.linalg.svd(H)\n",
    "    R = Vt.T @ U.T\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[1, :] *= -1\n",
    "        R = Vt.T @ U.T\n",
    "    t = centroid_dst - R @ centroid_src\n",
    "    return R, t\n",
    "\n",
    "def usac_rigid_transform(src_points, dst_points, *, num_iterations: int = 100,\n",
    "                         inlier_threshold: float = 50.0, min_inliers: int = 60):\n",
    "    best_inlier_count = 0\n",
    "    best_R = best_t = best_inlier_mask = None\n",
    "    N = src_points.shape[0]\n",
    "    if N < 2:\n",
    "        raise ValueError(\"ä¾†æºé»æ•¸ä¸è¶³\")\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        if N < 8:\n",
    "            break\n",
    "        indices = np.random.choice(N, 8, replace=False)\n",
    "        src_sample = src_points[indices]\n",
    "        dst_sample = dst_points[indices]\n",
    "        if np.linalg.norm(src_sample[1] - src_sample[0]) < 1e-10:\n",
    "            continue\n",
    "        R_cand, t_cand = estimate_rigid_transform(src_sample, dst_sample)\n",
    "        src_transformed = (R_cand @ src_points.T).T + t_cand\n",
    "        distances = np.linalg.norm(dst_points - src_transformed, axis=1)\n",
    "        inlier_mask = distances < inlier_threshold\n",
    "        inlier_count = np.sum(inlier_mask)\n",
    "        if inlier_count > best_inlier_count and inlier_count >= min_inliers:\n",
    "            best_inlier_count = inlier_count\n",
    "            best_R, best_t, best_inlier_mask = R_cand, t_cand, inlier_mask\n",
    "            break\n",
    "    if best_inlier_mask is None or np.sum(best_inlier_mask) < min_inliers:\n",
    "        raise ValueError(\"USAC æœªæ‰¾åˆ°è¶³å¤ å…§é»\")\n",
    "    src_inliers = src_points[best_inlier_mask]\n",
    "    dst_inliers = dst_points[best_inlier_mask]\n",
    "    best_R, best_t = estimate_rigid_transform(src_inliers, dst_inliers)\n",
    "    return best_R, best_t, best_inlier_mask\n",
    "\n",
    "# ---------------------------\n",
    "# 3. ICP / CPD / Normalâ€‘ICP\n",
    "# ---------------------------\n",
    "\n",
    "def icp_with_weights(source_points, target_points, weights, *, max_iterations: int = 500, tolerance: float = 1e-5):#-20\n",
    "    R_total = np.eye(2)\n",
    "    t_total = np.zeros(2)\n",
    "    prev_error = float(\"inf\")\n",
    "    for iteration in range(max_iterations):\n",
    "        transformed_source = (R_total @ source_points.T).T + t_total\n",
    "        nbrs = NearestNeighbors(n_neighbors=1).fit(target_points)\n",
    "        distances, indices = nbrs.kneighbors(transformed_source)\n",
    "        closest_points = target_points[indices.flatten()]\n",
    "        error = np.sum(weights * (distances.flatten() ** 2)) / (np.sum(weights) + 1e-9)\n",
    "        if abs(prev_error - error) < tolerance and error < 1:\n",
    "            break\n",
    "        prev_error = error\n",
    "        src_centroid = np.average(transformed_source, axis=0, weights=weights)\n",
    "        tgt_centroid = np.average(closest_points, axis=0, weights=weights)\n",
    "        src_cent = transformed_source - src_centroid\n",
    "        tgt_cent = closest_points - tgt_centroid\n",
    "        H = (weights[:, None] * src_cent).T @ tgt_cent\n",
    "        U, _, Vt = np.linalg.svd(H)\n",
    "        R_delta = Vt.T @ U.T\n",
    "        if np.linalg.det(R_delta) < 0:\n",
    "            Vt[1, :] *= -1\n",
    "            R_delta = Vt.T @ U.T\n",
    "        t_delta = tgt_centroid - R_delta @ src_centroid\n",
    "        R_total = R_delta @ R_total\n",
    "        t_total = R_delta @ t_total + t_delta\n",
    "    return R_total, t_total, prev_error\n",
    "\n",
    "def cpd_rigid_registration(source_points, target_points, *, max_iterations: int = 50, tolerance: float = 1e-3):\n",
    "    reg = RigidRegistration(X=target_points, Y=source_points,\n",
    "                            max_iterations=max_iterations, tolerance=tolerance)\n",
    "    Y_reg, (s, R, t) = reg.register()\n",
    "    return s, R, t, Y_reg\n",
    "\n",
    "def compute_normals(points, k: int = 40):\n",
    "    if len(points) < 3:\n",
    "        return np.zeros_like(points)\n",
    "    actual_k = min(k, len(points) - 1)\n",
    "    nbrs = NearestNeighbors(n_neighbors=actual_k).fit(points)\n",
    "    _, indices = nbrs.kneighbors(points)\n",
    "    normals = np.zeros_like(points)\n",
    "    for i, neighbors in enumerate(indices):\n",
    "        cov_matrix = np.cov(points[neighbors].T)\n",
    "        eigvals, eigvecs = np.linalg.eigh(cov_matrix)\n",
    "        normals[i] = eigvecs[:, 0]\n",
    "    return normals / (np.linalg.norm(normals, axis=1, keepdims=True) + 1e-9)\n",
    "\n",
    "def normal_icp(source_points, target_points, weights, *, alpha: float = 0.1, gamma: float = 0.8,\n",
    "               max_iterations: int = 500, tolerance: float = 1e-5):\n",
    "    source_normals = compute_normals(source_points)\n",
    "    target_normals = compute_normals(target_points)\n",
    "    R_total = np.eye(2)\n",
    "    t_total = np.zeros(2)\n",
    "    prev_error = float(\"inf\")\n",
    "    for iteration in range(max_iterations):\n",
    "        transformed_source = (R_total @ source_points.T).T + t_total\n",
    "        nbrs = NearestNeighbors(n_neighbors=1).fit(target_points)\n",
    "        distances, indices = nbrs.kneighbors(transformed_source)\n",
    "        indices = np.clip(indices.flatten(), 0, len(target_normals) - 1)\n",
    "        closest_points = target_points[indices]\n",
    "        closest_normals = target_normals[indices]\n",
    "        normal_dot = np.einsum(\"ij,ij->i\", source_normals, closest_normals)\n",
    "        normal_errors = np.arccos(np.clip(normal_dot, -1, 1))\n",
    "        weighted_normals = np.exp(-normal_errors / (2 * alpha)) ** gamma\n",
    "        combined_weights = weights * distances.flatten() * weighted_normals\n",
    "        error = np.sum(combined_weights * (distances.flatten() ** 2)) / (np.sum(combined_weights) + 1e-9)\n",
    "        if abs(prev_error - error) < tolerance and error < 1:\n",
    "            break\n",
    "        prev_error = error\n",
    "        src_centroid = np.average(transformed_source, axis=0, weights=combined_weights)\n",
    "        tgt_centroid = np.average(closest_points, axis=0, weights=combined_weights)\n",
    "        src_cent = transformed_source - src_centroid\n",
    "        tgt_cent = closest_points - tgt_centroid\n",
    "        H = (combined_weights[:, None] * src_cent).T @ tgt_cent\n",
    "        U, _, Vt = np.linalg.svd(H)\n",
    "        R_delta = Vt.T @ U.T\n",
    "        if np.linalg.det(R_delta) < 0:\n",
    "            Vt[1, :] *= -1\n",
    "            R_delta = Vt.T @ U.T\n",
    "        t_delta = tgt_centroid - R_delta @ src_centroid\n",
    "        R_total = R_delta @ R_total\n",
    "        t_total = R_delta @ t_total + t_delta\n",
    "    return R_total, t_total, prev_error\n",
    "\n",
    "def fill_line_gaps(points, *, max_distance: float = 3.0, max_iter: int = 5):\n",
    "    pts = points.copy()\n",
    "    for _ in range(max_iter):\n",
    "        nbrs = NearestNeighbors(n_neighbors=2).fit(pts)\n",
    "        distances, indices = nbrs.kneighbors(pts)\n",
    "        new_pts = []\n",
    "        for i in range(len(pts)):\n",
    "            d = distances[i, 1]\n",
    "            if d > max_distance:\n",
    "                p1, p2 = pts[i], pts[indices[i, 1]]\n",
    "                num_insert = int(d // max_distance)\n",
    "                for n in range(1, num_insert + 1):\n",
    "                    new_pts.append(p1 + (p2 - p1) * n / (num_insert + 1))\n",
    "        if not new_pts:\n",
    "            break\n",
    "        pts = np.vstack([pts, np.array(new_pts)])\n",
    "    return pts\n",
    "\n",
    "\"\"\"{\n",
    "        \"name\": \"red01\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red01\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red01\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red01/Image_20240321100710525.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321100710525.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red01_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"red02\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red02\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red02\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red02/Image_20240321104026349.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321104026349.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red02_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"red03\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red03\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red03\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red03/Image_20240321105545542.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321105545542.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red03_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"red04\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red04\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red04\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red04/Image_20240321111055812.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321111055812.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red04_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"red05\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red05\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red05\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red05/Image_20240321112738655.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321112738655.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red05_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"red06\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red06\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red06\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red06/Image_20240321114408009.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321114408009.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red06_combined.xlsx\",\n",
    "    },\n",
    "\"\"\"\n",
    "# ---------------------------\n",
    "# 4. DATASETS åƒæ•¸æ¸…å–®\n",
    "# ---------------------------\n",
    "DATASETS: List[Dict] = [\n",
    "{\n",
    "        \"name\": \"red01\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red01\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red01\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red01/Image_20240321100710525.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321100710525.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red01_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"red02\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red02\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red02\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red02/Image_20240321104026349.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321104026349.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red02_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"red03\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red03\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red03\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red03/Image_20240321105545542.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321105545542.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red03_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"red04\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red04\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red04\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red04/Image_20240321111055812.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321111055812.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red04_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"red05\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red05\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red05\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red05/Image_20240321112738655.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321112738655.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red05_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"red06\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red06\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/red06\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/red06/Image_20240321114408009.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321114408009.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/red06_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"white01\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white01\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/white01\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white01/Image_20240321143412883.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321143412883.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/white01_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"white02\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white02\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/white02\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white02/Image_20240321145312162.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321145312162.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/white02_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"white03\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white03\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/white03\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white03/Image_20240321151040617.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321151040617.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/white03_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"white04\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white04\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/white04\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white04/Image_20240321152853920.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321152853920.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/white04_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"white05\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white05\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/white05\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white05/Image_20240321154611642.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321154611642.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/white05_combined.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"white06\",\n",
    "        \"csv_dir\":  r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white06\",\n",
    "        \"img_dir\":  r\"/media/dc0206/Crucial X6/GMM20/20240329_DATA2/20240329_DATA/NTHU_5x/white06\",\n",
    "        \"template_csv\": r\"/media/dc0206/Crucial X6/GMM20/EdgeFinderResult/white06/Image_20240321160945507.csv\",\n",
    "        \"template_img\": r\"/media/dc0206/Crucial X6/GMM20/crop_w5.bmp\",\n",
    "        \"first_img\": \"Image_20240321160945507.bmp\",\n",
    "        \"final_xlsx\": r\"/media/dc0206/Crucial X6/GMM20/white06_combined.xlsx\",\n",
    "    },\n",
    "\n",
    "    # --- æ–°è³‡æ–™é›†è«‹ç›´æ¥åœ¨æ­¤è™•ç¹¼çºŒåŠ å…¥ ------------------------------------\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [red01] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red01_combined.xlsxï¼Œç¸½è€—æ™‚ 42.5s\n",
      "âœ… [red01] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red01_combined.xlsxï¼Œç¸½è€—æ™‚ 42.6s\n",
      "âœ… [red02] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red02_combined.xlsxï¼Œç¸½è€—æ™‚ 46.3s\n",
      "âœ… [red02] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red02_combined.xlsxï¼Œç¸½è€—æ™‚ 46.4s\n",
      "âœ… [red03] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red03_combined.xlsxï¼Œç¸½è€—æ™‚ 27.4s\n",
      "âœ… [red03] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red03_combined.xlsxï¼Œç¸½è€—æ™‚ 27.5s\n",
      "âœ… [red04] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red04_combined.xlsxï¼Œç¸½è€—æ™‚ 29.4s\n",
      "âœ… [red04] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red04_combined.xlsxï¼Œç¸½è€—æ™‚ 29.4s\n",
      "âœ… [red05] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red05_combined.xlsxï¼Œç¸½è€—æ™‚ 28.1s\n",
      "âœ… [red05] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red05_combined.xlsxï¼Œç¸½è€—æ™‚ 28.2s\n",
      "âœ… [red06] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red06_combined.xlsxï¼Œç¸½è€—æ™‚ 28.7s\n",
      "âœ… [red06] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/red06_combined.xlsxï¼Œç¸½è€—æ™‚ 28.7s\n",
      "âœ… [white01] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white01_combined.xlsxï¼Œç¸½è€—æ™‚ 37.3s\n",
      "âœ… [white01] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white01_combined.xlsxï¼Œç¸½è€—æ™‚ 37.4s\n",
      "âœ… [white02] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white02_combined.xlsxï¼Œç¸½è€—æ™‚ 37.2s\n",
      "âœ… [white02] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white02_combined.xlsxï¼Œç¸½è€—æ™‚ 37.3s\n",
      "âœ… [white03] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white03_combined.xlsxï¼Œç¸½è€—æ™‚ 29.7s\n",
      "âœ… [white03] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white03_combined.xlsxï¼Œç¸½è€—æ™‚ 29.7s\n",
      "âœ… [white04] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white04_combined.xlsxï¼Œç¸½è€—æ™‚ 30.6s\n",
      "âœ… [white04] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white04_combined.xlsxï¼Œç¸½è€—æ™‚ 30.7s\n",
      "âœ… [white05] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white05_combined.xlsxï¼Œç¸½è€—æ™‚ 47.4s\n",
      "âœ… [white05] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white05_combined.xlsxï¼Œç¸½è€—æ™‚ 47.4s\n",
      "âœ… [white06] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white06_combined.xlsxï¼Œç¸½è€—æ™‚ 32.8s\n",
      "âœ… [white06] å®Œæˆï¼Œæª”æ¡ˆï¼š/media/dc0206/Crucial X6/GMM20/white06_combined.xlsxï¼Œç¸½è€—æ™‚ 32.9s\n"
     ]
    }
   ],
   "source": [
    "# 5. å–®è³‡æ–™é›†å®Œæ•´æµç¨‹\n",
    "\n",
    "def process_dataset(cfg: Dict):\n",
    "    start = time.time()\n",
    "    # === è®€ cfg ===\n",
    "    csv_directory     = cfg[\"csv_dir\"]\n",
    "    image_directory   = cfg[\"img_dir\"]\n",
    "    template_csv_path = cfg[\"template_csv\"]\n",
    "    template_path     = cfg[\"template_img\"]\n",
    "    first_img         = cfg[\"first_img\"]\n",
    "    final_output      = cfg[\"final_xlsx\"]\n",
    "\n",
    "    # === æ­¥é©Ÿè€—æ™‚çµ±è¨ˆ ===\n",
    "    step_times = {\n",
    "        \"template\": [],\n",
    "        \"csv_read\": [],\n",
    "        \"denoise\": [],\n",
    "        \"usac\": [],\n",
    "        \"icp\": [],\n",
    "    }\n",
    "\n",
    "# === 1. ç¬¬ä¸€å¼µå½±åƒå»ºç«‹åƒè€ƒ ===\n",
    "# === 0. è®€å–æ¨¡æ¿ ===\n",
    "    t0 = time.time()\n",
    "    template_data = pd.read_csv(template_csv_path)\n",
    "    template_points = template_data[['PosX','PosY']].values\n",
    "    first_image = cv2.imread(os.path.join(image_directory, first_img), cv2.IMREAD_GRAYSCALE)\n",
    "    template_img = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "    res_match = cv2.matchTemplate(first_image, template_img, cv2.TM_CCOEFF_NORMED)\n",
    "    _, _, _, first_tl = cv2.minMaxLoc(res_match)\n",
    "    first_br = ( first_tl[0] + template_img.shape[1],\n",
    "                first_tl[1] + template_img.shape[0] )\n",
    "    step_times[\"template\"].append(time.time() - t0)\n",
    "\n",
    "    # ç¯©é¸æ¨¡æ¿å€åŸŸ\n",
    "    template_pts_filtered = template_points[\n",
    "        (template_points[:,0] >= first_tl[0]) & (template_points[:,0] <= first_br[0]) &\n",
    "        (template_points[:,1] >= first_tl[1]) & (template_points[:,1] <= first_br[1])\n",
    "    ]\n",
    "\n",
    "    h,w = template_img.shape[:2]\n",
    "    # ç”¨ç¬¬ä¸€æ¬¡çš„ first_tl ç®—æ­£ä¸­é–“\n",
    "    region_center = np.array([ first_tl[0] + w/2.0,\n",
    "                            first_tl[1] + h/2.0 ])\n",
    "    if len(template_pts_filtered) < 3:\n",
    "        raise ValueError(\"æ¨¡æ¿å€åŸŸé»ä¸è¶³\")\n",
    "    \n",
    "    # === 1. ç¬¬ä¸€å¼µå½±åƒå»ºç«‹åƒè€ƒ ===\n",
    "    t0 = time.time()\n",
    "    df_first = pd.read_csv(os.path.join(csv_directory, first_img.replace('.bmp','.csv')))\n",
    "    pts1 = df_first[['PosX','PosY']].values\n",
    "    cond1 = (\n",
    "        (pts1[:,0] >= first_tl[0]) & (pts1[:,0] <= first_br[0]) &\n",
    "        (pts1[:,1] >= first_tl[1]) & (pts1[:,1] <= first_br[1])\n",
    "    )\n",
    "    first_matched = pts1[cond1]\n",
    "    # åªå–éæ¿¾å¾Œçš„é»\n",
    "    ref = filter_noise_points_weighted(first_matched)[0]\n",
    "    ref = ensure_two_points_in_circle_iterative(ref, radius=0.5, max_iter=300)\n",
    "    ref = fill_line_gaps(ref, max_distance=2.0, max_iter=500)\n",
    "    step_times[\"csv_read\"].append(time.time() - t0)\n",
    "\n",
    "    # åˆå§‹åŒ– results èˆ‡ prev_inc\n",
    "    results = []\n",
    "    prev_inc = np.zeros(2)\n",
    "\n",
    "    # ç¬¬ä¸€å¼µç›´æ¥å­˜\n",
    "    results.append({\n",
    "        \"image_file\": first_img,\n",
    "        \"rotation_matrix\": np.eye(2).tolist(),\n",
    "        \"translation_vector\": [0,0],\n",
    "        \"incremental_displacement\": [0,0],\n",
    "        \"incremental_disp_norm\": 0.0,\n",
    "        \"displacement\": [0,0],\n",
    "        \"displacement_norm\": 0.0,\n",
    "        \"alignment_error\": 0.0,\n",
    "    })\n",
    "\n",
    "    # --- è¿´åœˆè™•ç†å…¶é¤˜å½±åƒ ---\n",
    "    imgs = sorted(glob.glob(os.path.join(image_directory, '*.bmp')))\n",
    "    csvs = sorted(glob.glob(os.path.join(csv_directory, '*.csv')))\n",
    "    for idx in range(1, len(imgs)):\n",
    "        # 2-1 æ¨¡æ¿åŒ¹é…æ‰¾ tl, center\n",
    "        t0 = time.time()\n",
    "        im = cv2.imread(imgs[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        res = cv2.matchTemplate(im, template_img, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, tl = cv2.minMaxLoc(res)\n",
    "        step_times[\"template\"].append(time.time() - t0)\n",
    "        # å€åŸŸä¸­å¿ƒ\n",
    "        region_center = np.array([ tl[0] + w/2.0,\n",
    "                                   tl[1] + h/2.0 ])\n",
    "\n",
    "        # 2-2 è®€ CSV + ç¯©é»\n",
    "        t0 = time.time()\n",
    "        dfc = pd.read_csv(csvs[idx])\n",
    "        pts = dfc[['PosX','PosY']].values\n",
    "        cond = ((pts[:,0]>=tl[0])&(pts[:,0]<=tl[0]+w)&\n",
    "                (pts[:,1]>=tl[1])&(pts[:,1]<=tl[1]+h))\n",
    "        cur = pts[cond]\n",
    "        step_times[\"csv_read\"].append(time.time() - t0)\n",
    "        if len(cur)<3 or len(ref)<3:\n",
    "            continue\n",
    "\n",
    "        # 2-3 é›œè¨Šéæ¿¾ + è£œé»\n",
    "        t0 = time.time()\n",
    "        # åªå–éæ¿¾å¾Œçš„é»\n",
    "        cur = filter_noise_points_weighted(cur)[0]\n",
    "        cur = ensure_two_points_in_circle_iterative(cur, radius=0.5, max_iter=300)\n",
    "        cur = fill_line_gaps(cur, max_distance=2.0, max_iter=500)\n",
    "        step_times[\"denoise\"].append(time.time() - t0)\n",
    "\n",
    "        # 2-4 æ¬Šé‡\n",
    "        dens = compute_local_density(cur, k=25)\n",
    "        dens = (dens - dens.min())/(dens.max()-dens.min()+1e-9)\n",
    "\n",
    "        # 2-5 USAC\n",
    "        t0 = time.time()\n",
    "        nbrs = NearestNeighbors(n_neighbors=1).fit(ref)\n",
    "        _,idx2 = nbrs.kneighbors(cur)\n",
    "        tgt = ref[idx2.flatten()]\n",
    "        try:\n",
    "            R_u, t_u, _ = usac_rigid_transform(cur, tgt, inlier_threshold=40, min_inliers=20)\n",
    "        except:\n",
    "            R_u, t_u = np.eye(2), np.zeros(2)\n",
    "        step_times[\"usac\"].append(time.time() - t0)\n",
    "\n",
    "        # 2-6 ICP + CPD + Normal-ICP\n",
    "        t0 = time.time()\n",
    "        R_p, t_p, e_p = icp_with_weights(cur, ref, dens)\n",
    "        try:\n",
    "            _, R_c, t_c, _ = cpd_rigid_registration(cur, ref, max_iterations=100, tolerance=1e-3)\n",
    "        except:\n",
    "            R_c, t_c = np.eye(2), np.zeros(2)\n",
    "        R_n, t_n, e_n = normal_icp((R_c@cur.T).T + t_c, ref, dens)\n",
    "        if e_p < e_n:\n",
    "            R_f, t_f, err_f = R_p, t_p, e_p\n",
    "        else:\n",
    "            R_f = R_n @ R_c\n",
    "            t_f = R_n @ t_c + t_n\n",
    "            err_f = e_n\n",
    "        step_times[\"icp\"].append(time.time() - t0)\n",
    "        #print(region_center)\n",
    "        # 2-7 è¨ˆç®—å¢é‡ä½ç§»ï¼šè€ƒæ…®æ—‹è½‰+å¹³ç§»çš„ region_center\n",
    "        transformed_center = R_f @ region_center + t_f\n",
    "        #transformed_center = region_center + t_f\n",
    "        inc = transformed_center - region_center\n",
    "        disp = inc - prev_inc\n",
    "        prev_inc = inc.copy()\n",
    "\n",
    "        # 2-8 æ”¶é›†çµæœ\n",
    "        results.append({\n",
    "            \"image_file\": os.path.basename(imgs[idx]),\n",
    "            \"rotation_matrix\":          R_f.tolist(),\n",
    "            \"translation_vector\":       t_f.tolist(),\n",
    "            \"incremental_displacement\": inc.tolist(),\n",
    "            \"incremental_disp_norm\":    float(np.linalg.norm(inc)),\n",
    "            \"displacement\":             disp.tolist(),\n",
    "            \"displacement_norm\":        float(np.linalg.norm(disp)),\n",
    "            \"alignment_error\":          float(err_f),\n",
    "        })\n",
    "\n",
    "\n",
    "    # === 3. è¼¸å‡º Excel ===\n",
    "    os.makedirs(os.path.dirname(final_output), exist_ok=True)\n",
    "    pd.DataFrame(results).to_excel(final_output, index=False)\n",
    "    print(f\"âœ… [{cfg['name']}] å®Œæˆï¼Œæª”æ¡ˆï¼š{final_output}ï¼Œç¸½è€—æ™‚ {(time.time()-start):.1f}s\")\n",
    "    # === 4. ç•«æ­¥é©Ÿè€—æ™‚åœ“é¤…åœ– ===\n",
    "    labels = list(step_times.keys())\n",
    "    totals = [sum(step_times[k]) for k in labels]\n",
    "    if sum(totals)>0:\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.pie(totals, labels=labels, autopct=\"%1.1f%%\", startangle=45)\n",
    "        plt.axis(\"equal\")\n",
    "        chart_dir = os.path.join(os.path.dirname(final_output),\"time_charts\")\n",
    "        os.makedirs(chart_dir, exist_ok=True)\n",
    "        pie_path = os.path.join(chart_dir, f\"{cfg['name']}_time_pie.png\")\n",
    "        plt.savefig(pie_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"âœ… [{cfg['name']}] å®Œæˆï¼Œæª”æ¡ˆï¼š{final_output}ï¼Œç¸½è€—æ™‚ {(time.time()-start):.1f}s\")\n",
    "\n",
    "def main():\n",
    "    for cfg in DATASETS:\n",
    "        try:\n",
    "            process_dataset(cfg)\n",
    "        except Exception as e:\n",
    "            print(f\"[{cfg['name']}] å¤±æ•—ï¼š{e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
